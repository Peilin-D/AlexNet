{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 3, 29, 28,  3, 36, 28, 13,  9, 32, 11], dtype=int32), array([[[[ 0.6016826 ,  0.24945885, -0.42792562],\n",
      "         [ 0.61699253,  0.26476875, -0.41261572],\n",
      "         [ 0.62177151,  0.26954752, -0.40783694],\n",
      "         ..., \n",
      "         [ 0.86283624,  0.57087857, -0.14668339],\n",
      "         [ 0.86283624,  0.57087857, -0.14668339],\n",
      "         [ 0.86283624,  0.57087857, -0.14668339]],\n",
      "\n",
      "        [[ 0.62177151,  0.26954752, -0.40783694],\n",
      "         [ 0.62177151,  0.26954752, -0.40783694],\n",
      "         [ 0.62177151,  0.26954752, -0.40783694],\n",
      "         ..., \n",
      "         [ 0.8580575 ,  0.56609976, -0.15146215],\n",
      "         [ 0.84274757,  0.55078965, -0.16677207],\n",
      "         [ 0.84274757,  0.55078965, -0.16677207]],\n",
      "\n",
      "        [[ 0.62177151,  0.26954752, -0.40783694],\n",
      "         [ 0.62177151,  0.26954752, -0.40783694],\n",
      "         [ 0.62450337,  0.27227965, -0.40510482],\n",
      "         ..., \n",
      "         [ 0.85482025,  0.56286252, -0.15469943],\n",
      "         [ 0.84274757,  0.55078965, -0.16677207],\n",
      "         [ 0.84274757,  0.55078965, -0.16677207]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.14698698, -0.48647922, -1.06341994],\n",
      "         [ 0.15669903, -0.47676718, -1.05370796],\n",
      "         [ 0.16792679, -0.46553895, -1.04247975],\n",
      "         ..., \n",
      "         [ 0.37530828, -0.21798036, -0.81500977],\n",
      "         [ 0.30363744, -0.2896513 , -0.88668072],\n",
      "         [ 0.22636853, -0.36692011, -0.96394956]],\n",
      "\n",
      "        [[ 0.14388981, -0.4895764 , -1.06651711],\n",
      "         [ 0.14388981, -0.4895764 , -1.06651711],\n",
      "         [ 0.14388981, -0.4895764 , -1.06651711],\n",
      "         ..., \n",
      "         [ 0.3779119 , -0.21537673, -0.81240642],\n",
      "         [ 0.29453674, -0.29875177, -0.89578134],\n",
      "         [ 0.21999668, -0.37329194, -0.97032136]],\n",
      "\n",
      "        [[ 0.12167712, -0.51178908, -1.08872986],\n",
      "         [ 0.12167712, -0.51178908, -1.08872986],\n",
      "         [ 0.12167712, -0.51178908, -1.08872986],\n",
      "         ..., \n",
      "         [ 0.36321032, -0.23007843, -0.82710797],\n",
      "         [ 0.29079407, -0.30249456, -0.89952397],\n",
      "         [ 0.21999668, -0.37329194, -0.97032136]]],\n",
      "\n",
      "\n",
      "       [[[ 1.42883396,  0.66359258,  0.11581056],\n",
      "         [ 0.99970037,  0.33747968, -0.08557418],\n",
      "         [ 1.17744505,  0.70421505,  0.46936366],\n",
      "         ..., \n",
      "         [-1.32728946, -1.3405807 , -1.41753447],\n",
      "         [-1.34276402, -1.3483181 , -1.42527175],\n",
      "         [-1.4086026 , -1.38936865, -1.4663223 ]],\n",
      "\n",
      "        [[ 1.22045159,  0.40255359,  0.03490224],\n",
      "         [ 1.01637137,  0.32162577,  0.11199199],\n",
      "         [ 1.15007198,  0.68049574,  0.64480788],\n",
      "         ..., \n",
      "         [-1.37507439, -1.38836575, -1.46531928],\n",
      "         [-1.40318155, -1.40873563, -1.48568928],\n",
      "         [-1.45739055, -1.4381566 , -1.51511025]],\n",
      "\n",
      "        [[ 1.30470455,  0.48202971,  0.07043814],\n",
      "         [ 1.16593266,  0.48487279,  0.21909529],\n",
      "         [ 1.29909909,  0.8417747 ,  0.79003912],\n",
      "         ..., \n",
      "         [-1.32327759, -1.33656895, -1.41352248],\n",
      "         [-1.36788595, -1.37344003, -1.45039368],\n",
      "         [-1.42285943, -1.40362537, -1.48057902]],\n",
      "\n",
      "        ..., \n",
      "        [[-0.83783394, -1.00744581, -0.7120803 ],\n",
      "         [-0.55944598, -0.77720243, -0.50490338],\n",
      "         [-0.75444227, -1.00701642, -0.82440907],\n",
      "         ..., \n",
      "         [-1.55818534, -1.50341761, -1.59225953],\n",
      "         [-1.53906107, -1.48429322, -1.59097517],\n",
      "         [-1.49894142, -1.44417357, -1.55844986]],\n",
      "\n",
      "        [[-0.68843538, -0.81730747, -0.53309137],\n",
      "         [-0.54596579, -0.77014494, -0.50099993],\n",
      "         [-0.69704384, -1.00256395, -0.80742258],\n",
      "         ..., \n",
      "         [-1.59826255, -1.5912801 , -1.57667446],\n",
      "         [-1.47529781, -1.4683156 , -1.45371008],\n",
      "         [-1.55296087, -1.54597843, -1.5313729 ]],\n",
      "\n",
      "        [[-0.94536996, -1.08568192, -0.76380682],\n",
      "         [-0.71009868, -0.96195668, -0.6811322 ],\n",
      "         [-0.72248954, -1.04011428, -0.84296739],\n",
      "         ..., \n",
      "         [-1.56654751, -1.5635761 , -1.54295373],\n",
      "         [-1.42610633, -1.42313492, -1.40251279],\n",
      "         [-1.5081836 , -1.50521219, -1.48459005]]],\n",
      "\n",
      "\n",
      "       [[[ 1.59830105,  2.02696967,  2.24256039],\n",
      "         [ 1.79112923,  2.21979785,  2.43538857],\n",
      "         [ 1.79484832,  2.20896029,  2.39543748],\n",
      "         ..., \n",
      "         [-0.65798509, -0.98626411, -0.98902398],\n",
      "         [-0.65798509, -0.98626411, -0.98902398],\n",
      "         [-0.67254174, -1.00082076, -1.00358057]],\n",
      "\n",
      "        [[ 1.77195561,  2.20062423,  2.4162147 ],\n",
      "         [ 1.84446049,  2.27312922,  2.4887197 ],\n",
      "         [ 1.8768661 ,  2.29828835,  2.48476553],\n",
      "         ..., \n",
      "         [-0.62669164, -0.95497078, -0.95773059],\n",
      "         [-0.62940538, -0.9576844 , -0.96044415],\n",
      "         [-0.64862257, -0.97690177, -0.97966152]],\n",
      "\n",
      "        [[ 1.75425637,  2.20787001,  2.41724062],\n",
      "         [ 1.80470324,  2.23754025,  2.45729899],\n",
      "         [ 1.82276177,  2.2504456 ,  2.45360041],\n",
      "         ..., \n",
      "         [-0.57224572, -0.90886116, -0.90745282],\n",
      "         [-0.58417559, -0.92079109, -0.91938263],\n",
      "         [-0.5950771 , -0.9316926 , -0.93028414]],\n",
      "\n",
      "        ..., \n",
      "        [[-0.75577712, -1.22962308, -1.16370428],\n",
      "         [-0.62784386, -1.1016897 , -1.08989286],\n",
      "         [-0.67088097, -1.14472699, -1.13293004],\n",
      "         ..., \n",
      "         [-0.99952602, -1.30657256, -1.15273881],\n",
      "         [-1.02921259, -1.31382155, -1.16370428],\n",
      "         [-1.0219022 , -1.29920089, -1.16370428]],\n",
      "\n",
      "        [[-0.6538164 , -1.1276623 , -1.11586547],\n",
      "         [-0.70838797, -1.18223393, -1.1626575 ],\n",
      "         [-0.66426837, -1.13811445, -1.12631762],\n",
      "         ..., \n",
      "         [-1.00356245, -1.31728482, -1.16370428],\n",
      "         [-1.0219022 , -1.30651128, -1.16370428],\n",
      "         [-1.0219022 , -1.29920089, -1.16370428]],\n",
      "\n",
      "        [[-0.77860719, -1.25245321, -1.16370428],\n",
      "         [-0.69829869, -1.17214465, -1.1566925 ],\n",
      "         [-0.71356225, -1.18740809, -1.16370428],\n",
      "         ..., \n",
      "         [-1.01125813, -1.3249805 , -1.16370428],\n",
      "         [-1.00473714, -1.28934622, -1.16109586],\n",
      "         [-1.01465595, -1.29195452, -1.16370428]]],\n",
      "\n",
      "\n",
      "       ..., \n",
      "       [[[-1.04191482, -0.44695505, -1.36537468],\n",
      "         [-0.79213208, -0.19717227, -1.11559188],\n",
      "         [-0.76919895, -0.17423916, -1.09265888],\n",
      "         ..., \n",
      "         [-0.02900678,  0.70192599, -0.91022056],\n",
      "         [-0.1845762 ,  0.565781  , -1.1102016 ],\n",
      "         [ 0.05605099,  0.80640817, -0.86957449]],\n",
      "\n",
      "        [[-1.13835359, -0.54339379, -1.46181357],\n",
      "         [-0.77726752, -0.18230769, -1.10072768],\n",
      "         [-0.85845357, -0.26349404, -1.18846297],\n",
      "         ..., \n",
      "         [-0.27878928,  0.45035434, -1.15196776],\n",
      "         [-0.20450754,  0.53269458, -1.10054839],\n",
      "         [-0.34073493,  0.39333236, -1.22901988]],\n",
      "\n",
      "        [[-1.12791395, -0.53295428, -1.45137393],\n",
      "         [-0.79040778, -0.19544828, -1.113868  ],\n",
      "         [-0.91424233, -0.3192828 , -1.26995623],\n",
      "         ..., \n",
      "         [-0.54044992,  0.17600435, -1.35385823],\n",
      "         [-0.16506547,  0.55337363, -1.01072776],\n",
      "         [-0.46995246,  0.24848665, -1.31396568]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.14025274,  1.18198049, -0.78537273],\n",
      "         [ 0.2288796 ,  1.27060735, -0.69674587],\n",
      "         [ 0.27713376,  1.31886148, -0.64849174],\n",
      "         ..., \n",
      "         [ 0.08277451,  1.14392674, -0.97882366],\n",
      "         [ 0.22722632,  1.23010468, -0.87322128],\n",
      "         [ 0.15971391,  1.16259205, -0.94073367]],\n",
      "\n",
      "        [[ 0.07915447,  1.12088227, -0.84647077],\n",
      "         [ 0.14293547,  1.18466294, -0.78268975],\n",
      "         [ 0.16230562,  1.20039976, -0.75605279],\n",
      "         ..., \n",
      "         [ 0.23631148,  1.27667105, -0.83914858],\n",
      "         [ 0.14657946,  1.13559544, -0.96079922],\n",
      "         [ 0.20493403,  1.1939503 , -0.90244466]],\n",
      "\n",
      "        [[ 0.19638696,  1.23811448, -0.72923851],\n",
      "         [ 0.15475209,  1.19647956, -0.77087313],\n",
      "         [ 0.04371909,  1.07526374, -0.8615405 ],\n",
      "         ..., \n",
      "         [ 0.36085588,  1.36373448, -0.73959172],\n",
      "         [ 0.15477715,  1.11880577, -0.96509516],\n",
      "         [ 0.26458779,  1.22861671, -0.85528451]]],\n",
      "\n",
      "\n",
      "       [[[ 0.47771403,  0.22683628, -0.74631155],\n",
      "         [ 0.50744206,  0.25656426, -0.71658355],\n",
      "         [ 0.51546806,  0.26459029, -0.70855749],\n",
      "         ..., \n",
      "         [-0.95466864, -0.68818432, -1.32392216],\n",
      "         [-0.99965674, -0.73317236, -1.36891019],\n",
      "         [-1.03661823, -0.77013385, -1.40587175]],\n",
      "\n",
      "        [[ 0.46205753,  0.21117976, -0.76196814],\n",
      "         [ 0.49178553,  0.24090776, -0.73224014],\n",
      "         [ 0.51491618,  0.26403844, -0.70910925],\n",
      "         ..., \n",
      "         [-1.00288928, -0.73640484, -1.37214279],\n",
      "         [-1.02718568, -0.76070142, -1.39643919],\n",
      "         [-1.05911231, -0.79262787, -1.42836583]],\n",
      "\n",
      "        [[ 0.4552201 ,  0.20434223, -0.76880556],\n",
      "         [ 0.47927567,  0.22839792, -0.74475002],\n",
      "         [ 0.50585628,  0.25497848, -0.71816957],\n",
      "         ..., \n",
      "         [-1.03661823, -0.78777236, -1.39705241],\n",
      "         [-1.04589534, -0.79704946, -1.40632963],\n",
      "         [-1.04147387, -0.79262787, -1.40190792]],\n",
      "\n",
      "        ..., \n",
      "        [[ 0.60817379,  0.84820056, -0.37039948],\n",
      "         [ 0.5517748 ,  0.80754387, -0.41233075],\n",
      "         [ 0.381228  ,  0.64573056, -0.57485157],\n",
      "         ..., \n",
      "         [ 0.34742072,  0.72439295, -0.59012842],\n",
      "         [ 0.05836987,  0.44925836, -0.9070105 ],\n",
      "         [ 0.36663133,  0.76411605, -0.61194193]],\n",
      "\n",
      "        [[ 0.49852344,  0.76986384, -0.49174303],\n",
      "         [ 0.6270684 ,  0.9216724 , -0.33993459],\n",
      "         [ 0.51368326,  0.82119268, -0.44041419],\n",
      "         ..., \n",
      "         [-0.27108341,  0.10787091, -1.20268703],\n",
      "         [-0.37869686,  0.0062405 , -1.32226646],\n",
      "         [-0.21187533,  0.17589797, -1.16111696]],\n",
      "\n",
      "        [[ 0.1565285 ,  0.44550687, -0.85183376],\n",
      "         [ 0.14383514,  0.4328135 , -0.85525054],\n",
      "         [ 0.00918721,  0.32177916, -0.94649637],\n",
      "         ..., \n",
      "         [-0.16699539,  0.19828461, -1.07570887],\n",
      "         [-0.18220675,  0.18307321, -1.09250569],\n",
      "         [-0.25240338,  0.11287657, -1.13218176]]],\n",
      "\n",
      "\n",
      "       [[[-0.9645108 , -0.96381742, -0.99276292],\n",
      "         [-0.85912377, -0.85843039, -0.88737589],\n",
      "         [-0.88561296, -0.88491958, -0.91386509],\n",
      "         ..., \n",
      "         [-1.44943392, -1.40024805, -1.34837317],\n",
      "         [-1.44943392, -1.40024805, -1.34837317],\n",
      "         [-1.46559799, -1.41641223, -1.36453724]],\n",
      "\n",
      "        [[-0.93795043, -0.93725705, -0.96620256],\n",
      "         [-0.8541317 , -0.85343832, -0.88238388],\n",
      "         [-0.88455993, -0.88386655, -0.91281199],\n",
      "         ..., \n",
      "         [-1.37896132, -1.32977557, -1.2779007 ],\n",
      "         [-1.42200339, -1.37281775, -1.32094264],\n",
      "         [-1.42087984, -1.37169409, -1.31981909]],\n",
      "\n",
      "        [[-0.89522594, -0.89453256, -0.92347807],\n",
      "         [-0.83519804, -0.83450466, -0.86345023],\n",
      "         [-0.88286602, -0.88217264, -0.91111803],\n",
      "         ..., \n",
      "         [-1.40806258, -1.35887694, -1.30700195],\n",
      "         [-1.41838813, -1.36920249, -1.3173275 ],\n",
      "         [-1.41397274, -1.36478698, -1.31291211]],\n",
      "\n",
      "        ..., \n",
      "        [[-0.82017344, -0.78715181, -0.81609738],\n",
      "         [-0.83583885, -0.80281729, -0.83176285],\n",
      "         [-0.80222899, -0.76920748, -0.79815292],\n",
      "         ..., \n",
      "         [-1.09332156, -1.04413581, -0.99226087],\n",
      "         [-1.10696948, -1.05778384, -1.00590897],\n",
      "         [-1.10884821, -1.05966258, -1.00778759]],\n",
      "\n",
      "        [[-0.84673309, -0.81371158, -0.84265697],\n",
      "         [-0.84360057, -0.810579  , -0.83952445],\n",
      "         [-0.78670579, -0.75368416, -0.78262967],\n",
      "         ..., \n",
      "         [-1.09178436, -1.04259872, -0.99072361],\n",
      "         [-1.05087566, -1.00169003, -0.94981498],\n",
      "         [-1.08542097, -1.03623521, -0.98436028]],\n",
      "\n",
      "        [[-0.86752623, -0.83450466, -0.86345023],\n",
      "         [-0.84360057, -0.810579  , -0.83952445],\n",
      "         [-0.76564366, -0.73262209, -0.76156753],\n",
      "         ..., \n",
      "         [-1.14226711, -1.09308136, -1.04120636],\n",
      "         [-1.12770271, -1.07851696, -1.02664208],\n",
      "         [-1.11298597, -1.06380022, -1.01192534]]]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(): \n",
    "    images, labels, keypts = distorted_inputs(10)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    print sess.run([labels, images])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distorted_inputs(batch_size):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    keypts_list = []\n",
    "    i = 0\n",
    "    for folder in os.listdir('train'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        cur_list = ['train/' + folder + '/' + img \n",
    "                    for img in os.listdir('train/' + folder) if img.endswith('.jpg')]\n",
    "        label_list.extend([i] * len(cur_list))\n",
    "        keypts_list.extend(get_keypts(folder, cur_list, train=True))\n",
    "        img_list.extend(cur_list)\n",
    "        i += 1\n",
    "    \n",
    "    input_tensor = zip(img_list, label_list, keypts_list)\n",
    "    random.shuffle(input_tensor)\n",
    "    \n",
    "    data_queue = tf.FIFOQueue(capacity=100, dtypes=[tf.string, tf.int32, tf.float32], shapes=[[],[],[36]])\n",
    "    enqueue_op = data_queue.enqueue_many(zip(*input_tensor))\n",
    "    qr = tf.train.QueueRunner(data_queue, [enqueue_op] * 4)\n",
    "    tf.train.add_queue_runner(qr)\n",
    "    \n",
    "    img_file, label, keypt = data_queue.dequeue()\n",
    "    raw = tf.read_file(img_file)\n",
    "    img = tf.image.decode_jpeg(raw)\n",
    "    resized_img = tf.image.resize_images(img, tf.constant([227, 227]))\n",
    "    fliped_img = tf.image.random_flip_left_right(resized_img)\n",
    "    distorted_img = tf.image.random_brightness(fliped_img, max_delta=50)\n",
    "    distorted_img = tf.image.random_contrast(distorted_img, lower=0.2, upper=1.8)\n",
    "    float_img = tf.image.per_image_standardization(distorted_img)\n",
    "    float_img.set_shape([227, 227, 3])\n",
    "    images, labels, keypts = tf.train.shuffle_batch([float_img, label, keypt],\n",
    "                                   batch_size=batch_size,\n",
    "                                   capacity=1000 + 3 * batch_size,\n",
    "                                   min_after_dequeue=1000)\n",
    "    return images, labels, keypts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs(batch_size):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    keypts_list = []\n",
    "    i = 0\n",
    "    for folder in os.listdir('test'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        cur_list = ['test/' + folder + '/' + img \n",
    "                    for img in os.listdir('test/' + folder) if img.endswith('.jpg')]\n",
    "        label_list.extend([i] * len(cur_list))\n",
    "        keypts_list.extend(get_keypts(folder, cur_list, train=False))\n",
    "        img_list.extend(cur_list)\n",
    "        i += 1\n",
    "        \n",
    "    data_queue = tf.FIFOQueue(capacity=50, dtypes=[tf.string, tf.int32, tf.float32], shapes=[[],[],[36]])\n",
    "    enqueue_op = data_queue.enqueue_many([img_list, label_list, keypts_list])\n",
    "    qr = tf.train.QueueRunner(data_queue, [enqueue_op] * 4)\n",
    "    tf.train.add_queue_runner(qr)\n",
    "    \n",
    "    img_file, label, keypt = data_queue.dequeue()\n",
    "    raw = tf.read_file(img_file)\n",
    "    img = tf.image.decode_jpeg(raw)\n",
    "    \n",
    "    resized_img = tf.image.resize_images(img, tf.constant([227, 227]))\n",
    "    float_img = tf.image.per_image_standardization(resized_img)\n",
    "    float_img.set_shape([227, 227, 3])\n",
    "    images, labels, keypts  = tf.train.batch([float_img, label, keypt],\n",
    "                                    batch_size=batch_size,\n",
    "                                    capacity=100 + batch_size)\n",
    "    return images, labels, keypts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_train_test():\n",
    "    train_map = {}\n",
    "    for annotations in os.listdir('ImageSplits'):\n",
    "        if annotations == 'actions.txt':\n",
    "            continue\n",
    "        if annotations.endswith('train.txt'):\n",
    "            cls = '_'.join(annotations.split('_')[:-1])\n",
    "            if cls not in train_map:\n",
    "                train_map[cls] = set()\n",
    "            with open('ImageSplits/' + annotations) as f:\n",
    "                for line in f:\n",
    "                    train_map[cls].add(line.strip())\n",
    "            train_folder = 'train/' + cls\n",
    "            test_folder = 'test/' + cls\n",
    "            if not os.path.exists(train_folder):\n",
    "                os.makedirs(train_folder)\n",
    "            if not os.path.exists(test_folder):\n",
    "                os.makedirs(test_folder)\n",
    "    for img_file in os.listdir('JPEGImages'):\n",
    "        cls = '_'.join(img_file.split('_')[:-1])\n",
    "        if img_file in train_map[cls]:\n",
    "            os.rename('JPEGImages/' + img_file, 'train/' + cls + '/' + img_file)\n",
    "        else:\n",
    "            os.rename('JPEGImages/' + img_file, 'test/' + cls + '/' + img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale_keypts(train):\n",
    "    if train:\n",
    "        path = 'train/'\n",
    "        keypts_path = 'keypts_train/'\n",
    "    else:\n",
    "        path = 'test/'\n",
    "        keypts_path = 'keypts_test/'\n",
    "    for folder in os.listdir('keypts'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        for keypts_file in os.listdir(keypts_path + folder):\n",
    "            if not keypts_file.endswith('.json'):\n",
    "                continue\n",
    "            with open(keypts_path + folder + '/' + keypts_file) as f:\n",
    "                keypts_js = json.load(f)\n",
    "            if len(keypts_js['people']) != 1:\n",
    "                continue\n",
    "            img_file = path + folder + '/' + '_'.join(keypts_file.split('_')[:-1]) + '.jpg'\n",
    "            base = keypts_file.rstrip('.json')\n",
    "            orig_shape = plt.imread(img_file).shape\n",
    "            ratio = (227.0 / orig_shape[1], 227.0 / orig_shape[0])\n",
    "            if not os.path.exists(path + folder + '/scaled_keypts'):\n",
    "                os.mkdir(path + folder + '/scaled_keypts')\n",
    "            with open(path + folder + '/scaled_keypts/' + base + '_scaled.json', 'wb+') as f:\n",
    "                people = keypts_js['people'][0]\n",
    "                keypts = people['pose_keypoints']\n",
    "                x = keypts[::3]\n",
    "                y = keypts[1::3]\n",
    "                c = keypts[2::3]\n",
    "                \n",
    "                xs = list(np.array(x) * ratio[0])\n",
    "                ys = list(np.array(y) * ratio[1])\n",
    "                \n",
    "                json.dump(zip(xs, ys), f)\n",
    "        print '%s done'%folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keypts(folder, img_list, train):\n",
    "    results = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    if train:\n",
    "        keypts_files = os.listdir('train/' + folder + '/scaled_keypts')\n",
    "    else:\n",
    "        keypts_files = os.listdir('test/' + folder + '/scaled_keypts')\n",
    "    while i < len(img_list) and j < len(keypts_files):\n",
    "        img_num = img_list[i].rstrip('.jpg').split('_')[-1]\n",
    "        result = []\n",
    "        if img_num in keypts_files[j]:\n",
    "            if train:\n",
    "                with open('train/' + folder + '/scaled_keypts/' + keypts_files[j]) as js_f:\n",
    "                    js = json.load(js_f)\n",
    "            else:\n",
    "                with open('test/' + folder + '/scaled_keypts/' + keypts_files[j]) as js_f:\n",
    "                    js = json.load(js_f)\n",
    "            result = [val for pair in js for val in pair]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            result = [0.0] * (18*2)\n",
    "            i += 1\n",
    "        results.append(result)\n",
    "    while i < len(img_list):\n",
    "        results.append([0.0] * 36)\n",
    "        i += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_summary(x):\n",
    "    tf.summary.scalar(x.op.name + '/min', tf.reduce_min(x))\n",
    "    tf.summary.scalar(x.op.name + '/max', tf.reduce_max(x))\n",
    "    tf.summary.scalar(x.op.name + '/mean', tf.reduce_mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images, keep_prob):\n",
    "     # 1st layer\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = tf.get_variable('weights', [11, 11, 3, 64], tf.float32, \n",
    "                                 tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        kernel = tf.verify_tensor_all_finite(kernel, 'kernel1 error')\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 4, 4, 1], padding='SAME')\n",
    "        biases = tf.get_variable('biases', [64], tf.float32, tf.constant_initializer(0.0))\n",
    "        conv1 = tf.nn.relu(conv + biases, name=scope.name)\n",
    "        conv1 = tf.verify_tensor_all_finite(conv1, 'conv1 error: ')\n",
    "        \n",
    "    lrn1 = tf.nn.local_response_normalization(conv1, alpha=1e-4, beta=0.75,\n",
    "                                              depth_radius=2, bias=2.0, name='lrn1')\n",
    "    pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    \n",
    "    # 2nd layer\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = tf.get_variable('weights', [5, 5, 64, 192], tf.float32, \n",
    "                                 tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        kernel = tf.verify_tensor_all_finite(kernel, 'kernel2 error')\n",
    "        conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.get_variable('biases', [192], tf.float32, tf.constant_initializer(0.0))\n",
    "        conv2 = tf.nn.relu(conv + biases, name=scope.name)\n",
    "        conv2 = tf.verify_tensor_all_finite(conv2, 'conv2 error: ')\n",
    "    \n",
    "    lrn2 = tf.nn.local_response_normalization(conv2, alpha=1e-4, beta=0.75, depth_radius=2, bias=2.0, name='lrn2')\n",
    "    pool2 = tf.nn.max_pool(lrn2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "        \n",
    "    \n",
    "    with tf.variable_scope('fc1') as scope:\n",
    "        W_fc1 = tf.get_variable('weights', [13 * 13 * 192, 1024], tf.float32, \n",
    "                                tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        b_fc1 = tf.get_variable('biases', [1024], tf.float32, tf.constant_initializer(0.0))\n",
    "        conv2_flat = tf.reshape(pool2, [-1, 13 * 13 * 192])\n",
    "        fc1 = tf.nn.relu(tf.matmul(conv2_flat, W_fc1) + b_fc1, name=scope.name)\n",
    "        fc1 = tf.verify_tensor_all_finite(fc1, 'fc1 error: ')\n",
    "    \n",
    "    # drop out\n",
    "    fc1_drop = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # read out layer\n",
    "    with tf.variable_scope('fc2') as scope:\n",
    "        W_fc2 = tf.get_variable('weights', [1024, 40], tf.float32, tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        b_fc2 = tf.get_variable('biases', [40], tf.float32, tf.constant_initializer(0.0))\n",
    "        y_conv = tf.add(tf.matmul(fc1_drop, W_fc2), b_fc2, name=scope.name)\n",
    "        y_conv = tf.verify_tensor_all_finite(y_conv, 'y_conv error: ')\n",
    "    \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(name, inputs, k_size, stride, padding, groups):\n",
    "    # k_size needs to be [h, w, num_in, num_out]\n",
    "    input_channels = int(inputs.get_shape()[-1])\n",
    "    assert input_channels % groups == 0\n",
    "    assert k_size[3] % groups == 0\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        k_size[2] /= groups\n",
    "        kernel = tf.get_variable('weights', k_size, tf.float32, \n",
    "                                 tf.truncated_normal_initializer(stddev=math.sqrt(2.0/(np.prod(k_size[:3])))),\n",
    "                                 tf.nn.l2_loss)\n",
    "        biases = tf.get_variable('biases', [k_size[3]], tf.float32, tf.constant_initializer(0.0))\n",
    "        if groups == 1:\n",
    "            conv = tf.nn.conv2d(inputs, kernel, stride, padding=padding)\n",
    "        else:\n",
    "            input_groups = tf.split(inputs, groups, 3)\n",
    "            kernel_groups = tf.split(kernel, groups, 3)\n",
    "            output_groups = [tf.nn.conv2d(i, k, stride, padding=padding) for i, k in zip(input_groups, kernel_groups)]\n",
    "            conv = tf.concat(output_groups, 3)\n",
    "            \n",
    "        conv = tf.verify_tensor_all_finite(conv, name + ' infinite error!!!')\n",
    "        return tf.nn.relu(conv + biases, name=scope.name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(name, inputs, output_size, relu=True):\n",
    "    # inputs should be flattened to a 2D tensor\n",
    "    input_size = int(inputs.get_shape()[1])\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        W = tf.get_variable('weights', [input_size, output_size], tf.float32, \n",
    "                            tf.truncated_normal_initializer(stddev=math.sqrt(2.0/input_size)),\n",
    "                            tf.nn.l2_loss)\n",
    "        b = tf.get_variable('biases', [output_size], tf.float32, tf.constant_initializer(0.0))\n",
    "        out = tf.verify_tensor_all_finite(tf.matmul(inputs, W) + b, name + ' inifite error!!!')\n",
    "        if relu:\n",
    "            return tf.nn.relu(out, name=scope.name)\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_deep(images, keep_prob, keypts=None):\n",
    "    # 1st layer\n",
    "    conv1 = conv_relu('conv1', images, [11, 11, 3, 96], [1, 4, 4, 1], 'VALID', 1)\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1, alpha=2e-5, beta=0.75,\n",
    "                                              depth_radius=2, bias=1.0, name='lrn1')\n",
    "    pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    \n",
    "    # 2nd layer\n",
    "    conv2 = conv_relu('conv2', pool1, [5, 5, 96, 256], [1, 1, 1, 1], 'SAME', 2)\n",
    "    lrn2 = tf.nn.local_response_normalization(conv2, alpha=2e-5, beta=0.75, \n",
    "                                              depth_radius=2, bias=1.0, name='lrn2')\n",
    "    pool2 = tf.nn.max_pool(lrn2, ksize=[1, 3, 3, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "    \n",
    "    # 3rd layer\n",
    "    conv3 = conv_relu('conv3', pool2, [3, 3, 256, 384], [1, 1, 1, 1], 'SAME', 1)\n",
    "        \n",
    "    # 4th layer\n",
    "    conv4 = conv_relu('conv4', conv3, [3, 3, 384, 384], [1, 1, 1, 1], 'SAME', 2)\n",
    "        \n",
    "    # 5th layer\n",
    "    conv5 = conv_relu('conv5', conv4, [3, 3, 384, 256], [1, 1, 1, 1], 'SAME', 2)\n",
    "    pool5 = tf.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool5')\n",
    "    \n",
    "    # 6th layer\n",
    "    pool5_flat = tf.reshape(pool5, [-1, 6 * 6 * 256])\n",
    "    if keypts is not None:\n",
    "        pool5_flat = tf.concat([pool5_flat, keypts], axis=1)\n",
    "    \n",
    "    fc6 = fc('fc6', pool5_flat, 4096)\n",
    "    \n",
    "    # drop out\n",
    "    fc6_drop = tf.nn.dropout(fc6, keep_prob)\n",
    "    \n",
    "    # 7th layer\n",
    "    fc7 = fc('fc7', fc6_drop, 4096)\n",
    "    \n",
    "    # drop out\n",
    "    fc7_drop = tf.nn.dropout(fc7, keep_prob)\n",
    "    \n",
    "    # readout layer\n",
    "    fc8 = fc('fc8', fc7_drop, 40, relu=False)\n",
    "    \n",
    "    return fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pretrained_weights(skip_layers, set_untrainable=True, warm_start=False):\n",
    "    weights = np.load('bvlc_alexnet.npy').item()\n",
    "    ops = []\n",
    "    trainables = tf.get_collection_ref(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    regularizations = tf.get_collection_ref(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    for layer in weights:\n",
    "        if layer not in skip_layers or warm_start:\n",
    "            with tf.variable_scope(layer, reuse=True) as scope:\n",
    "                kernel = tf.get_variable('weights')\n",
    "                ops.append(tf.assign(kernel, weights[layer][0]))\n",
    "                biases = tf.get_variable('biases')\n",
    "                ops.append(tf.assign(biases, weights[layer][1]))\n",
    "                if set_untrainable:\n",
    "                    trainables.remove(kernel)\n",
    "                    trainables.remove(biases)\n",
    "                    regularizations.remove(tf.losses.get_regularization_losses(scope.name)[0])\n",
    "    return tf.group(*ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits, labels, wd):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits))\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    return cross_entropy + wd * tf.add_n(reg_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(loss, global_step):\n",
    "    #lr = tf.train.exponential_decay(0.01, global_step, 3000, 0.1, True)\n",
    "    #opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    opt = tf.train.AdamOptimizer()\n",
    "    train_op = opt.minimize(loss, global_step)\n",
    "#     variable_averages = tf.train.ExponentialMovingAverage(0.999, global_step)\n",
    "#     variable_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "#     with tf.control_dependencies([train_op, variable_averages_op]):\n",
    "#         op = tf.no_op()\n",
    "#     return op\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(train_from_scratch=False):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        with tf.device('/cpu:0'):\n",
    "            images, labels, keypts = distorted_inputs(128)\n",
    "\n",
    "        pred = inference_deep(images, 0.5)\n",
    "        skip_layers = ['fc7', 'fc8']\n",
    "        load_op = load_pretrained_weights(skip_layers)\n",
    "        total_loss = loss(pred, labels, 0.0)\n",
    "        train_op = train(total_loss, global_step)\n",
    "\n",
    "        class _LoggerHook(tf.train.SessionRunHook):\n",
    "            def begin(self):\n",
    "                self._step = -1\n",
    "                self._start_time = time.time()\n",
    "\n",
    "            def before_run(self, run_context):\n",
    "                self._step += 1\n",
    "                if self._step % 100 == 0:\n",
    "                    return tf.train.SessionRunArgs(total_loss)\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "            def after_run(self, run_context, run_values):\n",
    "                if self._step % 100 == 0 :\n",
    "                    current_time = time.time()\n",
    "                    self._start_time = current_time\n",
    "                    loss_val = run_values.results\n",
    "                    format_str = '%s: step %d, loss = %.3f'\n",
    "                    print format_str % (datetime.now(), self._step, loss_val)\n",
    "                if self._step > 0 and self._step % 500 == 0:\n",
    "                    evaluate()\n",
    "\n",
    "        with tf.train.MonitoredTrainingSession(\n",
    "            checkpoint_dir='./tmp/ckpt_2',\n",
    "            hooks=[tf.train.StopAtStepHook(last_step=10000),\n",
    "                  tf.train.NanTensorHook(total_loss),\n",
    "                  _LoggerHook()]\n",
    "        ) as sess:\n",
    "            if not train_from_scratch:\n",
    "                sess.run(load_op)\n",
    "            while not sess.should_stop():\n",
    "                sess.run(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_2/model.ckpt-485\n",
      "INFO:tensorflow:Saving checkpoints for 485 into ./tmp/ckpt_2/model.ckpt.\n",
      "2017-09-11 21:35:41.888985: step 0, loss = 3.617\n",
      "INFO:tensorflow:global_step/sec: 0.270912\n",
      "2017-09-11 21:41:48.674516: step 100, loss = 2.739\n",
      "INFO:tensorflow:Saving checkpoints for 646 into ./tmp/ckpt_2/model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 0.240859\n",
      "2017-09-11 21:48:43.859718: step 200, loss = 2.717\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-3e3e738cc158>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_from_scratch)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    503\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    840\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    843\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(train=False, batch_size=1000):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        if train:\n",
    "            images, labels, _ = distorted_inputs(batch_size)\n",
    "        else:\n",
    "            images, labels, _ = inputs(batch_size)\n",
    "        pred = inference_deep(images, 1.0)\n",
    "        top_k_op = tf.nn.in_top_k(pred, labels, 1)\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(0.0)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "#         fix_v = {v.op.name: v for v in tf.trainable_variables() if not v.op.name.startswith('fc7') and not v.op.name.startswith('fc8')}\n",
    "#         ema_v = {k: v for k, v in variables_to_restore.items() if k.startswith('fc7') or k.startswith('fc8')}\n",
    "#         fix_v.update(ema_v)\n",
    "#         print fix_v\n",
    "        saver = tf.train.Saver()\n",
    "#         summary_op = tf.summary.merge_all()\n",
    "#         summary_write = tf.summary.FileWriter('./tmp/eval', g)\n",
    "        with tf.Session() as sess:\n",
    "            ckpt = tf.train.get_checkpoint_state('./tmp/ckpt_2')\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.all_model_checkpoint_paths[-2])\n",
    "            else:\n",
    "                print 'No checkpoint file found'\n",
    "                return\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess, coord)\n",
    "            try:\n",
    "                true_count = np.sum(sess.run(top_k_op))\n",
    "                precision = float(true_count) / batch_size\n",
    "                print 'precision: %.3f' % precision\n",
    "            except Exception as e:\n",
    "                print e\n",
    "            coord.request_stop()\n",
    "            coord.join(threads, stop_grace_period_secs=10)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_2/model.ckpt-323\n",
      "precision: 0.105\n"
     ]
    }
   ],
   "source": [
    "evaluate(False, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 20\n",
    "data = 10 * np.random.randn(N_SAMPLES, 4) + 1\n",
    "target = np.random.randint(0, 2, size=N_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  [-15.76484776  -1.97194302 -12.6300869    6.41410542]\n",
      "label:  [ 11.14868164   3.56267858 -15.04469109  -9.80371094]\n",
      "label:  [  8.03130531  10.71555138  -8.06960106 -20.6381073 ]\n",
      "label:  [-3.04018426  0.78890592 -5.47052765  0.58360696]\n",
      "label:  [-14.27897549   6.81375933  -6.26739216  -2.98046756]\n",
      "label:  [ 7.49180937  5.41993713 -1.01845872  7.99767256]\n",
      "label:  [  7.01992083  20.8553791   -0.63825244  -9.48780346]\n",
      "label:  [ -3.0049963  -11.29572868   0.87475055  -8.48777485]\n",
      "label:  [ 34.11064148  22.09499931   8.56626797  -1.86508656]\n",
      "label:  [ 13.01100731 -11.10157585   2.16470504 -11.60906315]\n",
      "label:  [ -9.11300278  21.20376587  -1.62195039   9.54562569]\n",
      "label:  [-19.14703941   1.41451061  -5.62721634  -2.7678473 ]\n",
      "label:  [ -1.06307101  -6.5821166  -15.47267818  -6.13916779]\n",
      "label:  [-3.30766511  3.53310657  0.40748918 -6.85776377]\n",
      "label:  [ 2.07924652 -0.27916488 -7.1269474   9.59386635]\n",
      "label:  [ 15.72919464   6.80227566   2.41824603   0.81573993]\n",
      "label:  [ -7.09694862  -2.00094342  12.21692467   5.83862686]\n",
      "label:  [-14.99517918 -12.00921249   2.41470122 -16.35501671]\n",
      "label:  [ 10.1179657    7.39433908 -11.46885109  24.31669807]\n",
      "label:  [-13.86396027   0.13506515  28.83094978   1.4432869 ]\n",
      "label:  [-15.76484776  -1.97194302 -12.6300869    6.41410542]\n",
      "label:  [ 11.14868164   3.56267858 -15.04469109  -9.80371094]\n",
      "label:  [  8.03130531  10.71555138  -8.06960106 -20.6381073 ]\n",
      "label:  [-3.04018426  0.78890592 -5.47052765  0.58360696]\n",
      "label:  [-14.27897549   6.81375933  -6.26739216  -2.98046756]\n",
      "label:  [ 7.49180937  5.41993713 -1.01845872  7.99767256]\n",
      "label:  [  7.01992083  20.8553791   -0.63825244  -9.48780346]\n",
      "label:  [ -3.0049963  -11.29572868   0.87475055  -8.48777485]\n",
      "label:  [ 34.11064148  22.09499931   8.56626797  -1.86508656]\n",
      "label:  [ 13.01100731 -11.10157585   2.16470504 -11.60906315]\n",
      "label:  [ -9.11300278  21.20376587  -1.62195039   9.54562569]\n",
      "label:  [-19.14703941   1.41451061  -5.62721634  -2.7678473 ]\n",
      "label:  [ -1.06307101  -6.5821166  -15.47267818  -6.13916779]\n",
      "label:  [-3.30766511  3.53310657  0.40748918 -6.85776377]\n",
      "label:  [ 2.07924652 -0.27916488 -7.1269474   9.59386635]\n",
      "label:  [ 15.72919464   6.80227566   2.41824603   0.81573993]\n",
      "label:  [ -7.09694862  -2.00094342  12.21692467   5.83862686]\n",
      "label:  [-14.99517918 -12.00921249   2.41470122 -16.35501671]\n",
      "label:  [ 10.1179657    7.39433908 -11.46885109  24.31669807]\n",
      "label:  [-13.86396027   0.13506515  28.83094978   1.4432869 ]\n",
      "label:  [-15.76484776  -1.97194302 -12.6300869    6.41410542]\n",
      "label:  [ 11.14868164   3.56267858 -15.04469109  -9.80371094]\n",
      "label:  [  8.03130531  10.71555138  -8.06960106 -20.6381073 ]\n",
      "label:  [-3.04018426  0.78890592 -5.47052765  0.58360696]\n",
      "label:  [-14.27897549   6.81375933  -6.26739216  -2.98046756]\n",
      "label:  [ 7.49180937  5.41993713 -1.01845872  7.99767256]\n",
      "label:  [  7.01992083  20.8553791   -0.63825244  -9.48780346]\n",
      "label:  [ -3.0049963  -11.29572868   0.87475055  -8.48777485]\n",
      "label:  [ 34.11064148  22.09499931   8.56626797  -1.86508656]\n",
      "label:  [ 13.01100731 -11.10157585   2.16470504 -11.60906315]\n",
      "label:  [ -9.11300278  21.20376587  -1.62195039   9.54562569]\n",
      "label:  [-19.14703941   1.41451061  -5.62721634  -2.7678473 ]\n",
      "label:  [ -1.06307101  -6.5821166  -15.47267818  -6.13916779]\n",
      "label:  [-3.30766511  3.53310657  0.40748918 -6.85776377]\n",
      "label:  [ 2.07924652 -0.27916488 -7.1269474   9.59386635]\n",
      "label:  [ 15.72919464   6.80227566   2.41824603   0.81573993]\n",
      "label:  [ -7.09694862  -2.00094342  12.21692467   5.83862686]\n",
      "label:  [-14.99517918 -12.00921249   2.41470122 -16.35501671]\n",
      "label:  [ 10.1179657    7.39433908 -11.46885109  24.31669807]\n",
      "label:  [-13.86396027   0.13506515  28.83094978   1.4432869 ]\n",
      "label:  [-15.76484776  -1.97194302 -12.6300869    6.41410542]\n",
      "label:  [ 11.14868164   3.56267858 -15.04469109  -9.80371094]\n",
      "label:  [  8.03130531  10.71555138  -8.06960106 -20.6381073 ]\n",
      "label:  [-3.04018426  0.78890592 -5.47052765  0.58360696]\n",
      "label:  [-14.27897549   6.81375933  -6.26739216  -2.98046756]\n",
      "label:  [ 7.49180937  5.41993713 -1.01845872  7.99767256]\n",
      "label:  [  7.01992083  20.8553791   -0.63825244  -9.48780346]\n",
      "label:  [ -3.0049963  -11.29572868   0.87475055  -8.48777485]\n",
      "label:  [ 34.11064148  22.09499931   8.56626797  -1.86508656]\n",
      "label:  [ 13.01100731 -11.10157585   2.16470504 -11.60906315]\n",
      "label:  [ -9.11300278  21.20376587  -1.62195039   9.54562569]\n",
      "label:  [-19.14703941   1.41451061  -5.62721634  -2.7678473 ]\n",
      "label:  [ -1.06307101  -6.5821166  -15.47267818  -6.13916779]\n",
      "label:  [-3.30766511  3.53310657  0.40748918 -6.85776377]\n",
      "label:  [ 2.07924652 -0.27916488 -7.1269474   9.59386635]\n",
      "label:  [ 15.72919464   6.80227566   2.41824603   0.81573993]\n",
      "label:  [ -7.09694862  -2.00094342  12.21692467   5.83862686]\n",
      "label:  [-14.99517918 -12.00921249   2.41470122 -16.35501671]\n",
      "label:  [ 10.1179657    7.39433908 -11.46885109  24.31669807]\n",
      "label:  [-13.86396027   0.13506515  28.83094978   1.4432869 ]\n",
      "label:  [-15.76484776  -1.97194302 -12.6300869    6.41410542]\n",
      "label:  [ 11.14868164   3.56267858 -15.04469109  -9.80371094]\n",
      "label:  [  8.03130531  10.71555138  -8.06960106 -20.6381073 ]\n",
      "label:  [-3.04018426  0.78890592 -5.47052765  0.58360696]\n",
      "label:  [-14.27897549   6.81375933  -6.26739216  -2.98046756]\n",
      "label:  [ 7.49180937  5.41993713 -1.01845872  7.99767256]\n",
      "label:  [  7.01992083  20.8553791   -0.63825244  -9.48780346]\n",
      "label:  [ -3.0049963  -11.29572868   0.87475055  -8.48777485]\n",
      "label:  [ 34.11064148  22.09499931   8.56626797  -1.86508656]\n",
      "label:  [ 13.01100731 -11.10157585   2.16470504 -11.60906315]\n",
      "label:  [ -9.11300278  21.20376587  -1.62195039   9.54562569]\n",
      "label:  [-19.14703941   1.41451061  -5.62721634  -2.7678473 ]\n",
      "label:  [ -1.06307101  -6.5821166  -15.47267818  -6.13916779]\n",
      "label:  [-3.30766511  3.53310657  0.40748918 -6.85776377]\n",
      "label:  [ 2.07924652 -0.27916488 -7.1269474   9.59386635]\n",
      "label:  [ 15.72919464   6.80227566   2.41824603   0.81573993]\n",
      "label:  [ -7.09694862  -2.00094342  12.21692467   5.83862686]\n",
      "label:  [-14.99517918 -12.00921249   2.41470122 -16.35501671]\n",
      "label:  [ 10.1179657    7.39433908 -11.46885109  24.31669807]\n",
      "label:  [-13.86396027   0.13506515  28.83094978   1.4432869 ]\n"
     ]
    }
   ],
   "source": [
    "NUM_THREADS = 4\n",
    "queue = tf.FIFOQueue(capacity=50, dtypes=[tf.float32, tf.int32], shapes=[[4], []])\n",
    "# queue  = tf.train.input_producer([data, target])\n",
    "enqueue_op = queue.enqueue_many([data, target])\n",
    "data_batch, label_batch = queue.dequeue()\n",
    "# create NUM_THREADS to do enqueue\n",
    "qr = tf.train.QueueRunner(queue, [enqueue_op] * NUM_THREADS)\n",
    "with tf.Session() as sess:\n",
    "    # Create a coordinator, launch the queue runner threads.\n",
    "    coord = tf.train.Coordinator()\n",
    "    enqueue_threads = qr.create_threads(sess, coord=coord, start=True)\n",
    "    for step in xrange(100): # do to 100 iterations\n",
    "        if coord.should_stop():\n",
    "            break\n",
    "        print 'label: ', sess.run(data_batch)\n",
    "    coord.request_stop()\n",
    "    coord.join(enqueue_threads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
