{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'HashTable' with these attrs.  Registered devices: [CPU], Registered kernels:\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_DOUBLE]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_FLOAT]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_INT32]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_INT64]\n  device='CPU'; key_dtype in [DT_INT64]; value_dtype in [DT_STRING]\n  device='CPU'; key_dtype in [DT_INT64]; value_dtype in [DT_INT64]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_STRING]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_BOOL]\n\n\t [[Node: hash_table = HashTable[container=\"\", key_dtype=DT_INT32, shared_name=\"\", use_node_name_sharing=false, value_dtype=DT_STRING]()]]\n\nCaused by op u'hash_table', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-7eaa424342c5>\", line 2, in <module>\n    val = distorted_inputs(10)\n  File \"<ipython-input-71-62132ef20c81>\", line 19, in distorted_inputs\n    tf.contrib.lookup.KeyValueTensorInitializer(img_dict.keys(), img_dict.values()), 'None')\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/lookup/lookup_ops.py\", line 236, in __init__\n    name=scope)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_lookup_ops.py\", line 48, in _hash_table\n    name=name)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'HashTable' with these attrs.  Registered devices: [CPU], Registered kernels:\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_DOUBLE]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_FLOAT]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_INT32]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_INT64]\n  device='CPU'; key_dtype in [DT_INT64]; value_dtype in [DT_STRING]\n  device='CPU'; key_dtype in [DT_INT64]; value_dtype in [DT_INT64]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_STRING]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_BOOL]\n\n\t [[Node: hash_table = HashTable[container=\"\", key_dtype=DT_INT32, shared_name=\"\", use_node_name_sharing=false, value_dtype=DT_STRING]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-7eaa424342c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistorted_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcoord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'HashTable' with these attrs.  Registered devices: [CPU], Registered kernels:\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_DOUBLE]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_FLOAT]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_INT32]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_INT64]\n  device='CPU'; key_dtype in [DT_INT64]; value_dtype in [DT_STRING]\n  device='CPU'; key_dtype in [DT_INT64]; value_dtype in [DT_INT64]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_STRING]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_BOOL]\n\n\t [[Node: hash_table = HashTable[container=\"\", key_dtype=DT_INT32, shared_name=\"\", use_node_name_sharing=false, value_dtype=DT_STRING]()]]\n\nCaused by op u'hash_table', defined at:\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-72-7eaa424342c5>\", line 2, in <module>\n    val = distorted_inputs(10)\n  File \"<ipython-input-71-62132ef20c81>\", line 19, in distorted_inputs\n    tf.contrib.lookup.KeyValueTensorInitializer(img_dict.keys(), img_dict.values()), 'None')\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/contrib/lookup/lookup_ops.py\", line 236, in __init__\n    name=scope)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_lookup_ops.py\", line 48, in _hash_table\n    name=name)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'HashTable' with these attrs.  Registered devices: [CPU], Registered kernels:\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_DOUBLE]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_FLOAT]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_INT32]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_INT64]\n  device='CPU'; key_dtype in [DT_INT64]; value_dtype in [DT_STRING]\n  device='CPU'; key_dtype in [DT_INT64]; value_dtype in [DT_INT64]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_STRING]\n  device='CPU'; key_dtype in [DT_STRING]; value_dtype in [DT_BOOL]\n\n\t [[Node: hash_table = HashTable[container=\"\", key_dtype=DT_INT32, shared_name=\"\", use_node_name_sharing=false, value_dtype=DT_STRING]()]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default(): \n",
    "    val = distorted_inputs(10)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    print sess.run(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distorted_inputs(batch_size):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    keypts_list = []\n",
    "    i = 0\n",
    "    for folder in os.listdir('train'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        cur_list = ['train/' + folder + '/' + img \n",
    "                    for img in os.listdir('train/' + folder) if img.endswith('.jpg')]\n",
    "        label_list.extend([i] * len(cur_list))\n",
    "        keypts_list.extend(get_keypts(folder, cur_list, train=True))\n",
    "        img_list.extend(cur_list)\n",
    "        i += 1\n",
    "    \n",
    "    input_tensor = zip(img_list, label_list, keypts_list)\n",
    "    random.shuffle(input_tensor)\n",
    "    \n",
    "    data_queue = tf.FIFOQueue(capacity=100, dtypes=[tf.string, tf.int32, tf.float32], shapes=[[],[],[36]])\n",
    "    enqueue_op = data_queue.enqueue_many(zip(*input_tensor))\n",
    "    qr = tf.train.QueueRunner(data_queue, [enqueue_op] * 4)\n",
    "    tf.train.add_queue_runner(qr)\n",
    "    \n",
    "    img_file, label, keypt = data_queue.dequeue()\n",
    "    raw = tf.read_file(img_file)\n",
    "    img = tf.image.decode_jpeg(raw)\n",
    "    resized_img = tf.image.resize_images(img, tf.constant([227, 227]))\n",
    "    fliped_img = tf.image.random_flip_left_right(resized_img)\n",
    "#     distorted_img = tf.image.random_brightness(fliped_img, max_delta=0.0)\n",
    "    distorted_img = tf.image.random_contrast(fliped_img, lower=0.2, upper=1.8)\n",
    "    float_img = tf.image.per_image_standardization(distorted_img)\n",
    "    float_img.set_shape([227, 227, 3])\n",
    "    images, labels, keypts = tf.train.shuffle_batch([float_img, label, keypt],\n",
    "                                   batch_size=batch_size,\n",
    "                                   capacity=1000 + 3 * batch_size,\n",
    "                                   min_after_dequeue=1000)\n",
    "    return images, labels, keypts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs(batch_size):\n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    keypts_list = []\n",
    "    i = 0\n",
    "    for folder in os.listdir('test'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        cur_list = ['test/' + folder + '/' + img \n",
    "                    for img in os.listdir('test/' + folder) if img.endswith('.jpg')]\n",
    "        label_list.extend([i] * len(cur_list))\n",
    "        keypts_list.extend(get_keypts(folder, cur_list, train=False))\n",
    "        img_list.extend(cur_list)\n",
    "        i += 1\n",
    "        \n",
    "    data_queue = tf.FIFOQueue(capacity=50, dtypes=[tf.string, tf.int32, tf.float32], shapes=[[],[],[36]])\n",
    "    enqueue_op = data_queue.enqueue_many([img_list, label_list, keypts_list])\n",
    "    qr = tf.train.QueueRunner(data_queue, [enqueue_op] * 4)\n",
    "    tf.train.add_queue_runner(qr)\n",
    "    \n",
    "    img_file, label, keypt = data_queue.dequeue()\n",
    "    raw = tf.read_file(img_file)\n",
    "    img = tf.image.decode_jpeg(raw)\n",
    "    \n",
    "    resized_img = tf.image.resize_images(img, tf.constant([227, 227]))\n",
    "    float_img = tf.image.per_image_standardization(resized_img)\n",
    "    float_img.set_shape([227, 227, 3])\n",
    "    images, labels, keypts  = tf.train.batch([float_img, label, keypt],\n",
    "                                    batch_size=batch_size,\n",
    "                                    capacity=100 + batch_size)\n",
    "    return images, labels, keypts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_train_test():\n",
    "    train_map = {}\n",
    "    for annotations in os.listdir('ImageSplits'):\n",
    "        if annotations == 'actions.txt':\n",
    "            continue\n",
    "        if annotations.endswith('train.txt'):\n",
    "            cls = '_'.join(annotations.split('_')[:-1])\n",
    "            if cls not in train_map:\n",
    "                train_map[cls] = set()\n",
    "            with open('ImageSplits/' + annotations) as f:\n",
    "                for line in f:\n",
    "                    train_map[cls].add(line.strip())\n",
    "            train_folder = 'train/' + cls\n",
    "            test_folder = 'test/' + cls\n",
    "            if not os.path.exists(train_folder):\n",
    "                os.makedirs(train_folder)\n",
    "            if not os.path.exists(test_folder):\n",
    "                os.makedirs(test_folder)\n",
    "    for img_file in os.listdir('JPEGImages'):\n",
    "        cls = '_'.join(img_file.split('_')[:-1])\n",
    "        if img_file in train_map[cls]:\n",
    "            os.rename('JPEGImages/' + img_file, 'train/' + cls + '/' + img_file)\n",
    "        else:\n",
    "            os.rename('JPEGImages/' + img_file, 'test/' + cls + '/' + img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale_keypts(train):\n",
    "    if train:\n",
    "        path = 'train/'\n",
    "        keypts_path = 'keypts_train/'\n",
    "    else:\n",
    "        path = 'test/'\n",
    "        keypts_path = 'keypts_test/'\n",
    "    for folder in os.listdir('keypts'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        for keypts_file in os.listdir(keypts_path + folder):\n",
    "            if not keypts_file.endswith('.json'):\n",
    "                continue\n",
    "            with open(keypts_path + folder + '/' + keypts_file) as f:\n",
    "                keypts_js = json.load(f)\n",
    "            if len(keypts_js['people']) != 1:\n",
    "                continue\n",
    "            img_file = path + folder + '/' + '_'.join(keypts_file.split('_')[:-1]) + '.jpg'\n",
    "            base = keypts_file.rstrip('.json')\n",
    "            orig_shape = plt.imread(img_file).shape\n",
    "            ratio = (227.0 / orig_shape[1], 227.0 / orig_shape[0])\n",
    "            if not os.path.exists(path + folder + '/scaled_keypts'):\n",
    "                os.mkdir(path + folder + '/scaled_keypts')\n",
    "            with open(path + folder + '/scaled_keypts/' + base + '_scaled.json', 'wb+') as f:\n",
    "                people = keypts_js['people'][0]\n",
    "                keypts = people['pose_keypoints']\n",
    "                x = keypts[::3]\n",
    "                y = keypts[1::3]\n",
    "                c = keypts[2::3]\n",
    "                \n",
    "                xs = list(np.array(x) * ratio[0])\n",
    "                ys = list(np.array(y) * ratio[1])\n",
    "                \n",
    "                json.dump(zip(xs, ys), f)\n",
    "        print '%s done'%folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keypts(folder, img_list, train):\n",
    "    results = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    if train:\n",
    "        keypts_files = os.listdir('train/' + folder + '/scaled_keypts')\n",
    "    else:\n",
    "        keypts_files = os.listdir('test/' + folder + '/scaled_keypts')\n",
    "    while i < len(img_list) and j < len(keypts_files):\n",
    "        img_num = img_list[i].rstrip('.jpg').split('_')[-1]\n",
    "        result = []\n",
    "        if img_num in keypts_files[j]:\n",
    "            if train:\n",
    "                with open('train/' + folder + '/scaled_keypts/' + keypts_files[j]) as js_f:\n",
    "                    js = json.load(js_f)\n",
    "            else:\n",
    "                with open('test/' + folder + '/scaled_keypts/' + keypts_files[j]) as js_f:\n",
    "                    js = json.load(js_f)\n",
    "            result = [val for pair in js for val in pair]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            result = [0.0] * (18*2)\n",
    "            i += 1\n",
    "        results.append(result)\n",
    "    while i < len(img_list):\n",
    "        results.append([0.0] * 36)\n",
    "        i += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_summary(x):\n",
    "    tf.summary.scalar(x.op.name + '/min', tf.reduce_min(x))\n",
    "    tf.summary.scalar(x.op.name + '/max', tf.reduce_max(x))\n",
    "    tf.summary.scalar(x.op.name + '/mean', tf.reduce_mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(name, inputs, k_size, stride, padding, groups):\n",
    "    # k_size needs to be [h, w, num_in, num_out]\n",
    "    input_channels = int(inputs.get_shape()[-1])\n",
    "    assert input_channels % groups == 0\n",
    "    assert k_size[3] % groups == 0\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        k_size[2] /= groups\n",
    "        kernel = tf.get_variable('weights', k_size, tf.float32, \n",
    "                                 tf.truncated_normal_initializer(stddev=math.sqrt(2.0/(np.prod(k_size[:3])))),\n",
    "                                 tf.nn.l2_loss)\n",
    "        biases = tf.get_variable('biases', [k_size[3]], tf.float32, tf.constant_initializer(0.0))\n",
    "        if groups == 1:\n",
    "            conv = tf.nn.conv2d(inputs, kernel, stride, padding=padding)\n",
    "        else:\n",
    "            input_groups = tf.split(inputs, groups, 3)\n",
    "            kernel_groups = tf.split(kernel, groups, 3)\n",
    "            output_groups = [tf.nn.conv2d(i, k, stride, padding=padding) for i, k in zip(input_groups, kernel_groups)]\n",
    "            conv = tf.concat(output_groups, 3)\n",
    "            \n",
    "        conv = tf.verify_tensor_all_finite(conv, name + ' infinite error!!!')\n",
    "        return tf.nn.relu(conv + biases, name=scope.name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(name, inputs, output_size, relu=True):\n",
    "    # inputs should be flattened to a 2D tensor\n",
    "    input_size = int(inputs.get_shape()[1])\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        W = tf.get_variable('weights', [input_size, output_size], tf.float32, \n",
    "                            tf.truncated_normal_initializer(stddev=math.sqrt(2.0/input_size)),\n",
    "                            tf.nn.l2_loss)\n",
    "        b = tf.get_variable('biases', [output_size], tf.float32, tf.constant_initializer(0.0))\n",
    "        out = tf.verify_tensor_all_finite(tf.matmul(inputs, W) + b, name + ' inifite error!!!')\n",
    "        if relu:\n",
    "            return tf.nn.relu(out, name=scope.name)\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images, keep_prob):\n",
    "    # 1st layer\n",
    "    conv1 = conv_relu('conv1', images, [11, 11, 3, 96], [1, 4, 4, 1], 'VALID', 1)\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1, alpha=2e-5, beta=0.75,\n",
    "                                              depth_radius=2, bias=1.0, name='lrn1')\n",
    "    pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    \n",
    "    # 2nd layer\n",
    "    conv2 = conv_relu('conv2', pool1, [5, 5, 96, 256], [1, 1, 1, 1], 'SAME', 2)\n",
    "    lrn2 = tf.nn.local_response_normalization(conv2, alpha=2e-5, beta=0.75, \n",
    "                                              depth_radius=2, bias=1.0, name='lrn2')\n",
    "    pool2 = tf.nn.max_pool(lrn2, ksize=[1, 3, 3, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "    \n",
    "    # 3rd layer\n",
    "    conv3 = conv_relu('conv3', pool2, [3, 3, 256, 384], [1, 1, 1, 1], 'SAME', 1)\n",
    "    \n",
    "#     shape = pool3.get_shape()[1:]\n",
    "#     print shape\n",
    "    flat3 = tf.reshape(conv3, [-1, 13 * 13 * 384])\n",
    "    fc4 = fc('fc4', flat3, 40, False)\n",
    "    \n",
    "    return fc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_deep(images, keep_prob, keypts=None):\n",
    "    # 1st layer\n",
    "    conv1 = conv_relu('conv1', images, [11, 11, 3, 96], [1, 4, 4, 1], 'VALID', 1)\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1, alpha=2e-5, beta=0.75,\n",
    "                                              depth_radius=2, bias=1.0, name='lrn1')\n",
    "    pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    \n",
    "    # 2nd layer\n",
    "    conv2 = conv_relu('conv2', pool1, [5, 5, 96, 256], [1, 1, 1, 1], 'SAME', 2)\n",
    "    lrn2 = tf.nn.local_response_normalization(conv2, alpha=2e-5, beta=0.75, \n",
    "                                              depth_radius=2, bias=1.0, name='lrn2')\n",
    "    pool2 = tf.nn.max_pool(lrn2, ksize=[1, 3, 3, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "    \n",
    "    # 3rd layer\n",
    "    conv3 = conv_relu('conv3', pool2, [3, 3, 256, 384], [1, 1, 1, 1], 'SAME', 1)\n",
    "        \n",
    "    # 4th layer\n",
    "    conv4 = conv_relu('conv4', conv3, [3, 3, 384, 384], [1, 1, 1, 1], 'SAME', 2)\n",
    "        \n",
    "    # 5th layer\n",
    "    conv5 = conv_relu('conv5', conv4, [3, 3, 384, 256], [1, 1, 1, 1], 'SAME', 2)\n",
    "    pool5 = tf.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool5')\n",
    "    \n",
    "    # 6th layer\n",
    "    pool5_flat = tf.reshape(pool5, [-1, 6 * 6 * 256])\n",
    "    if keypts is not None:\n",
    "        pool5_flat = tf.concat([pool5_flat, keypts], axis=1)\n",
    "    \n",
    "    fc6 = fc('fc6', pool5_flat, 4096)\n",
    "    \n",
    "    # drop out\n",
    "    fc6_drop = tf.nn.dropout(fc6, keep_prob)\n",
    "    \n",
    "    # 7th layer\n",
    "    fc7 = fc('fc7', fc6_drop, 4096)\n",
    "    \n",
    "    # drop out\n",
    "    fc7_drop = tf.nn.dropout(fc7, keep_prob)\n",
    "    \n",
    "    # readout layer\n",
    "    fc8 = fc('fc8', fc7_drop, 40, relu=False)\n",
    "    \n",
    "    return fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pretrained_weights(skip_layers, set_untrainable=True, warm_start=False):\n",
    "    weights = np.load('bvlc_alexnet.npy').item()\n",
    "    ops = []\n",
    "    trainables = tf.get_collection_ref(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    regularizations = tf.get_collection_ref(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    for layer in weights:\n",
    "        if layer not in skip_layers or warm_start:\n",
    "            with tf.variable_scope(layer, reuse=True) as scope:\n",
    "                kernel = tf.get_variable('weights')\n",
    "                ops.append(tf.assign(kernel, weights[layer][0]))\n",
    "                biases = tf.get_variable('biases')\n",
    "                ops.append(tf.assign(biases, weights[layer][1]))\n",
    "                if set_untrainable:\n",
    "                    trainables.remove(kernel)\n",
    "                    trainables.remove(biases)\n",
    "                    regularizations.remove(tf.losses.get_regularization_losses(scope.name)[0])\n",
    "    return tf.group(*ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits, labels, wd):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits))\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    return cross_entropy + wd * tf.add_n(reg_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(loss, global_step):\n",
    "    #lr = tf.train.exponential_decay(0.01, global_step, 3000, 0.1, True)\n",
    "    #opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    opt = tf.train.AdamOptimizer()\n",
    "    train_op = opt.minimize(loss, global_step)\n",
    "#     variable_averages = tf.train.ExponentialMovingAverage(0.999, global_step)\n",
    "#     variable_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "#     with tf.control_dependencies([train_op, variable_averages_op]):\n",
    "#         op = tf.no_op()\n",
    "#     return op\n",
    "    return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(train_from_scratch=False):\n",
    "    with tf.Graph().as_default() as g:\n",
    "      global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "      with tf.device('/cpu:0'):\n",
    "          images, labels, keypts = distorted_inputs(128)\n",
    "\n",
    "      pred = inference(images, 0.5)\n",
    "      skip_layers = ['conv4','conv5','fc6','fc7','fc8']\n",
    "      load_op = load_pretrained_weights(skip_layers)\n",
    "      total_loss = loss(pred, labels, 0.0)\n",
    "      train_op = train(total_loss, global_step)\n",
    "      \n",
    "      saver = tf.train.Saver(max_to_keep=10)\n",
    "      checkpoint_dir = './tmp/ckpt_3'\n",
    "      if not os.path.exists(checkpoint_dir):\n",
    "        os.mkdir(checkpoint_dir)\n",
    "      with tf.Session() as sess:\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "          saver.restore(sess, ckpt.all_model_checkpoint_paths[-1])\n",
    "        else:\n",
    "          print 'No checkpoint file found'\n",
    "          sess.run(tf.global_variables_initializer())\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess, coord)\n",
    "        if not train_from_scratch:\n",
    "          sess.run(load_op)\n",
    "        i = 0\n",
    "        max_iter = 10000\n",
    "        while i < max_iter and not coord.should_stop():\n",
    "          sess.run(train_op)\n",
    "          if i % 10 == 0:\n",
    "            loss_val = sess.run(total_loss)\n",
    "            print 'step %d, loss = %.3f' % (i, loss_val)\n",
    "          if i > 0 and i % 10 == 0:\n",
    "            saver.save(sess, checkpoint_dir + '/model_ckpt', global_step)\n",
    "            evaluate(False, 500)\n",
    "            evaluate(True, 1000)\n",
    "          i += 1\n",
    "#         class _LoggerHook(tf.train.SessionRunHook):\n",
    "#             def begin(self):\n",
    "#                 self._step = -1\n",
    "#                 self._start_time = time.time()\n",
    "\n",
    "#             def before_run(self, run_context):\n",
    "#                 self._step += 1\n",
    "#                 if self._step % 100 == 0:\n",
    "#                     return tf.train.SessionRunArgs(total_loss)\n",
    "#                 else:\n",
    "#                     return None\n",
    "\n",
    "#             def after_run(self, run_context, run_values):\n",
    "#                 if self._step % 100 == 0 :\n",
    "#                     current_time = time.time()\n",
    "#                     self._start_time = current_time\n",
    "#                     loss_val = run_values.results\n",
    "#                     format_str = '%s: step %d, loss = %.3f'\n",
    "#                     print format_str % (datetime.now(), self._step, loss_val)\n",
    "#                 if self._step > 0 and self._step % 500 == 0:\n",
    "#                     evaluate()\n",
    "\n",
    "#         with tf.train.MonitoredTrainingSession(\n",
    "# #             checkpoint_dir='./tmp/ckpt_3',\n",
    "#             hooks=[tf.train.StopAtStepHook(last_step=10000),\n",
    "#                   tf.train.NanTensorHook(total_loss),\n",
    "#                   _LoggerHook()]\n",
    "#         ) as sess:\n",
    "#             if not train_from_scratch:\n",
    "#                 sess.run(load_op)\n",
    "#             while not sess.should_stop():\n",
    "#                 sess.run(train_op)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-11\n",
      "step 0, loss = 114.816\n",
      "step 10, loss = 76.277\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-22\n",
      "precision: 0.206\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-22\n",
      "precision: 0.142\n",
      "step 20, loss = 31.838\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-32\n",
      "precision: 0.164\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-32\n",
      "precision: 0.181\n",
      "step 30, loss = 23.107\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-42\n",
      "precision: 0.198\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-42\n",
      "precision: 0.271\n",
      "step 40, loss = 13.155\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-52\n",
      "precision: 0.220\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-52\n",
      "precision: 0.397\n",
      "step 50, loss = 9.020\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-62\n",
      "precision: 0.250\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-62\n",
      "precision: 0.413\n",
      "step 60, loss = 7.543\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-72\n",
      "precision: 0.300\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-72\n",
      "precision: 0.460\n",
      "step 70, loss = 8.931\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-82\n",
      "precision: 0.204\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-82\n",
      "precision: 0.507\n",
      "step 80, loss = 4.647\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-92\n",
      "precision: 0.302\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-92\n",
      "precision: 0.542\n",
      "step 90, loss = 6.722\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-102\n",
      "precision: 0.366\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-102\n",
      "precision: 0.582\n",
      "step 100, loss = 5.229\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-112\n",
      "precision: 0.268\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-112\n",
      "precision: 0.592\n",
      "step 110, loss = 4.871\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-122\n",
      "precision: 0.194\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-122\n",
      "precision: 0.643\n",
      "step 120, loss = 7.837\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-132\n",
      "precision: 0.172\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-132\n",
      "precision: 0.609\n",
      "step 130, loss = 4.671\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-142\n",
      "precision: 0.364\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-142\n",
      "precision: 0.668\n",
      "step 140, loss = 4.713\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-152\n",
      "precision: 0.298\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-152\n",
      "precision: 0.650\n",
      "step 150, loss = 4.560\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-162\n",
      "precision: 0.276\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-162\n",
      "precision: 0.664\n",
      "step 160, loss = 3.410\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt_3/model_ckpt-172\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
      "\t [[Node: fifo_queue_EnqueueMany = QueueEnqueueManyV2[Tcomponents=[DT_STRING, DT_INT32, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](fifo_queue, fifo_queue_EnqueueMany/component_0, fifo_queue_EnqueueMany/component_1, fifo_queue_EnqueueMany/component_2)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-ca2f0cee21a1>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_from_scratch)\u001b[0m\n\u001b[1;32m     35\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/model_ckpt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m           \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-92995e3268a2>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(train, batch_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_checkpoint_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./tmp/ckpt_3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mckpt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_model_checkpoint_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mprint\u001b[0m \u001b[0;34m'No checkpoint file found'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1548\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(train=False, batch_size=1000):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        if train:\n",
    "            images, labels, _ = distorted_inputs(batch_size)\n",
    "        else:\n",
    "            images, labels, _ = inputs(batch_size)\n",
    "        pred = inference_deep(images, 1.0)\n",
    "#         cost = loss(pred, labels, 0.0)\n",
    "        top_k_op = tf.nn.in_top_k(pred, labels, 1)\n",
    "#         variable_averages = tf.train.ExponentialMovingAverage(0.0)\n",
    "#         variables_to_restore = variable_averages.variables_to_restore()\n",
    "#         fix_v = {v.op.name: v for v in tf.trainable_variables() if not v.op.name.startswith('fc7') and not v.op.name.startswith('fc8')}\n",
    "#         ema_v = {k: v for k, v in variables_to_restore.items() if k.startswith('fc7') or k.startswith('fc8')}\n",
    "#         fix_v.update(ema_v)\n",
    "#         print fix_v\n",
    "        saver = tf.train.Saver(tf.trainable_variables())\n",
    "#         summary_op = tf.summary.merge_all()\n",
    "#         summary_write = tf.summary.FileWriter('./tmp/eval', g)\n",
    "        with tf.Session() as sess:\n",
    "            ckpt = tf.train.get_checkpoint_state('./tmp/ckpt')\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.all_model_checkpoint_paths[-2])\n",
    "            else:\n",
    "                print 'No checkpoint file found'\n",
    "                return\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess, coord)\n",
    "            try:\n",
    "                true_count = np.sum(sess.run(top_k_op))\n",
    "                precision = float(true_count) / batch_size\n",
    "                print 'precision: %.3f' % precision\n",
    "            except Exception as e:\n",
    "                print e\n",
    "            coord.request_stop()\n",
    "            coord.join(threads, stop_grace_period_secs=10)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt/model.ckpt-1872\n"
     ]
    }
   ],
   "source": [
    "evaluate(False, 2800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
