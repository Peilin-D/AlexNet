{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(): \n",
    "    images, labels, keypts = distorted_inputs(10)\n",
    "    pred = inference_deep(images, 0.5, keypts)\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    kpys = sess.run(keypts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_train_test():\n",
    "    train_map = {}\n",
    "    for annotations in os.listdir('ImageSplits'):\n",
    "        if annotations == 'actions.txt':\n",
    "            continue\n",
    "        if annotations.endswith('train.txt'):\n",
    "            cls = '_'.join(annotations.split('_')[:-1])\n",
    "            if cls not in train_map:\n",
    "                train_map[cls] = set()\n",
    "            with open('ImageSplits/' + annotations) as f:\n",
    "                for line in f:\n",
    "                    train_map[cls].add(line.strip())\n",
    "            train_folder = 'train/' + cls\n",
    "            test_folder = 'test/' + cls\n",
    "            if not os.path.exists(train_folder):\n",
    "                os.makedirs(train_folder)\n",
    "            if not os.path.exists(test_folder):\n",
    "                os.makedirs(test_folder)\n",
    "    for img_file in os.listdir('JPEGImages'):\n",
    "        cls = '_'.join(img_file.split('_')[:-1])\n",
    "        if img_file in train_map[cls]:\n",
    "            os.rename('JPEGImages/' + img_file, 'train/' + cls + '/' + img_file)\n",
    "        else:\n",
    "            os.rename('JPEGImages/' + img_file, 'test/' + cls + '/' + img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rescale_keypts(train):\n",
    "    if train:\n",
    "        path = 'train/'\n",
    "        keypts_path = 'keypts_train/'\n",
    "    else:\n",
    "        path = 'test/'\n",
    "        keypts_path = 'keypts_test/'\n",
    "    for folder in os.listdir('keypts'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        for keypts_file in os.listdir(keypts_path + folder):\n",
    "            if not keypts_file.endswith('.json'):\n",
    "                continue\n",
    "            with open(keypts_path + folder + '/' + keypts_file) as f:\n",
    "                keypts_js = json.load(f)\n",
    "            if len(keypts_js['people']) != 1:\n",
    "                continue\n",
    "            img_file = path + folder + '/' + '_'.join(keypts_file.split('_')[:-1]) + '.jpg'\n",
    "            base = keypts_file.rstrip('.json')\n",
    "            orig_shape = plt.imread(img_file).shape\n",
    "            ratio = (227.0 / orig_shape[1], 227.0 / orig_shape[0])\n",
    "            if not os.path.exists(path + folder + '/scaled_keypts'):\n",
    "                os.mkdir(path + folder + '/scaled_keypts')\n",
    "            with open(path + folder + '/scaled_keypts/' + base + '_scaled.json', 'wb+') as f:\n",
    "                people = keypts_js['people'][0]\n",
    "                keypts = people['pose_keypoints']\n",
    "                x = keypts[::3]\n",
    "                y = keypts[1::3]\n",
    "                c = keypts[2::3]\n",
    "                \n",
    "                xs = list(np.array(x) * ratio[0])\n",
    "                ys = list(np.array(y) * ratio[1])\n",
    "                \n",
    "                json.dump(zip(xs, ys), f)\n",
    "        print '%s done'%folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_keypts(folder, img_list, train):\n",
    "    results = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    if train:\n",
    "        keypts_files = os.listdir('train/' + folder + '/scaled_keypts')\n",
    "    else:\n",
    "        keypts_files = os.listdir('test/' + folder + '/scaled_keypts')\n",
    "    while i < len(img_list) and j < len(keypts_files):\n",
    "        img_num = img_list[i].rstrip('.jpg').split('_')[-1]\n",
    "        result = []\n",
    "        if img_num in keypts_files[j]:\n",
    "            if train:\n",
    "                with open('train/' + folder + '/scaled_keypts/' + keypts_files[j]) as js_f:\n",
    "                    js = json.load(js_f)\n",
    "            else:\n",
    "                with open('test/' + folder + '/scaled_keypts/' + keypts_files[j]) as js_f:\n",
    "                    js = json.load(js_f)\n",
    "            result = [val for pair in js for val in pair]\n",
    "            i += 1\n",
    "            j += 1\n",
    "        else:\n",
    "            result = [0.0] * (18*2)\n",
    "            i += 1\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distorted_inputs(batch_size):\n",
    "    data_list = []\n",
    "    keypts_list = []\n",
    "    i = 0\n",
    "    for folder in os.listdir('train'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        img_list = ['train/' + folder + '/' + img \n",
    "                    for img in os.listdir('train/' + folder) if img.endswith('.jpg')]\n",
    "        cls_list = zip(img_list, [i] * len(img_list))\n",
    "        data_list.extend(cls_list)\n",
    "        keypts_list.extend(get_keypts(folder, img_list, train=True))\n",
    "        i += 1\n",
    "    \n",
    "    img_data = tf.constant(np.array(data_list))\n",
    "    keypts_data = tf.constant(np.array(keypts_list), dtype=tf.float32)\n",
    "    \n",
    "    data_queue = tf.train.input_producer(img_data)\n",
    "    keypts_queue = tf.train.input_producer(keypts_data)\n",
    "    \n",
    "    val = data_queue.dequeue()\n",
    "    keypt = keypts_queue.dequeue()\n",
    "    raw = tf.read_file(val[0])\n",
    "    img = tf.image.decode_jpeg(raw)\n",
    "    label = tf.string_to_number(val[1], tf.int32)\n",
    "    resized_img = tf.image.resize_images(img, tf.constant([227, 227]))\n",
    "    fliped_img = tf.image.random_flip_left_right(resized_img)\n",
    "    distorted_img = tf.image.random_brightness(fliped_img, max_delta=0.5)\n",
    "    distorted_img = tf.image.random_contrast(distorted_img, lower=0.2, upper=1.8)\n",
    "    float_img = tf.image.per_image_standardization(distorted_img)\n",
    "    float_img.set_shape([227, 227, 3])\n",
    "    images, labels, keypts = tf.train.shuffle_batch([float_img, label, keypt],\n",
    "                                   batch_size=batch_size,\n",
    "                                   capacity=100 + 3 * batch_size,\n",
    "                                   min_after_dequeue=100)\n",
    "    return images, labels, keypts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputs(batch_size):\n",
    "    data_list = []\n",
    "    keypts_list = []\n",
    "    i = 0\n",
    "    for folder in os.listdir('test'):\n",
    "        if folder == '.DS_Store':\n",
    "            continue\n",
    "        img_list = ['test/' + folder + '/' + img \n",
    "                    for img in os.listdir('test/' + folder) if img.endswith('.jpg')]\n",
    "        cls_list = zip(img_list, [i] * len(img_list))\n",
    "        data_list.extend(cls_list)\n",
    "        keypts_list.extend(get_keypts(folder, img_list, train=False))\n",
    "        i += 1\n",
    "        \n",
    "    data = tf.constant(np.array(data_list))\n",
    "    keypts_data = tf.constant(np.array(keypts_list), dtype=tf.float32)\n",
    "    \n",
    "    data_queue = tf.train.input_producer(data)\n",
    "    keypts_queue = tf.train.input_producer(keypts_data)\n",
    "    \n",
    "    val = data_queue.dequeue()\n",
    "    keypt = keypts_queue.dequeue()\n",
    "    raw = tf.read_file(val[0])\n",
    "    img = tf.image.decode_jpeg(raw)\n",
    "    label = tf.string_to_number(val[1], tf.int32)\n",
    "    \n",
    "    resized_img = tf.image.resize_images(img, tf.constant([227, 227]))\n",
    "    float_img = tf.image.per_image_standardization(resized_img)\n",
    "    float_img.set_shape([227, 227, 3])\n",
    "    images, labels, keypts  = tf.train.batch([float_img, label, keypt],\n",
    "                                    batch_size=batch_size,\n",
    "                                    capacity=100 + 3 * batch_size)\n",
    "    return images, labels, keypts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_summary(x):\n",
    "    tf.summary.scalar(x.op.name + '/min', tf.reduce_min(x))\n",
    "    tf.summary.scalar(x.op.name + '/max', tf.reduce_max(x))\n",
    "    tf.summary.scalar(x.op.name + '/mean', tf.reduce_mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images, keep_prob):\n",
    "     # 1st layer\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = tf.get_variable('weights', [11, 11, 3, 64], tf.float32, \n",
    "                                 tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        kernel = tf.verify_tensor_all_finite(kernel, 'kernel1 error')\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 4, 4, 1], padding='SAME')\n",
    "        biases = tf.get_variable('biases', [64], tf.float32, tf.constant_initializer(0.0))\n",
    "        conv1 = tf.nn.relu(conv + biases, name=scope.name)\n",
    "        conv1 = tf.verify_tensor_all_finite(conv1, 'conv1 error: ')\n",
    "        \n",
    "    lrn1 = tf.nn.local_response_normalization(conv1, alpha=1e-4, beta=0.75,\n",
    "                                              depth_radius=2, bias=2.0, name='lrn1')\n",
    "    pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    \n",
    "    # 2nd layer\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = tf.get_variable('weights', [5, 5, 64, 192], tf.float32, \n",
    "                                 tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        kernel = tf.verify_tensor_all_finite(kernel, 'kernel2 error')\n",
    "        conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.get_variable('biases', [192], tf.float32, tf.constant_initializer(0.0))\n",
    "        conv2 = tf.nn.relu(conv + biases, name=scope.name)\n",
    "        conv2 = tf.verify_tensor_all_finite(conv2, 'conv2 error: ')\n",
    "    \n",
    "    lrn2 = tf.nn.local_response_normalization(conv2, alpha=1e-4, beta=0.75, depth_radius=2, bias=2.0, name='lrn2')\n",
    "    pool2 = tf.nn.max_pool(lrn2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "        \n",
    "    \n",
    "    with tf.variable_scope('fc1') as scope:\n",
    "        W_fc1 = tf.get_variable('weights', [13 * 13 * 192, 1024], tf.float32, \n",
    "                                tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        b_fc1 = tf.get_variable('biases', [1024], tf.float32, tf.constant_initializer(0.0))\n",
    "        conv2_flat = tf.reshape(pool2, [-1, 13 * 13 * 192])\n",
    "        fc1 = tf.nn.relu(tf.matmul(conv2_flat, W_fc1) + b_fc1, name=scope.name)\n",
    "        fc1 = tf.verify_tensor_all_finite(fc1, 'fc1 error: ')\n",
    "    \n",
    "    # drop out\n",
    "    fc1_drop = tf.nn.dropout(fc1, keep_prob)\n",
    "    \n",
    "    # read out layer\n",
    "    with tf.variable_scope('fc2') as scope:\n",
    "        W_fc2 = tf.get_variable('weights', [1024, 40], tf.float32, tf.truncated_normal_initializer(stddev=1e-1))\n",
    "        b_fc2 = tf.get_variable('biases', [40], tf.float32, tf.constant_initializer(0.0))\n",
    "        y_conv = tf.add(tf.matmul(fc1_drop, W_fc2), b_fc2, name=scope.name)\n",
    "        y_conv = tf.verify_tensor_all_finite(y_conv, 'y_conv error: ')\n",
    "    \n",
    "    return y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_relu(name, inputs, k_size, stride, padding, groups):\n",
    "    # k_size needs to be [h, w, num_in, num_out]\n",
    "    input_channels = int(inputs.get_shape()[-1])\n",
    "    assert input_channels % groups == 0\n",
    "    assert k_size[3] % groups == 0\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        k_size[2] /= groups\n",
    "        kernel = tf.get_variable('weights', k_size, tf.float32, \n",
    "                                 tf.truncated_normal_initializer(stddev=math.sqrt(2.0/(np.prod(k_size[:3])))),\n",
    "                                 tf.nn.l2_loss)\n",
    "        biases = tf.get_variable('biases', [k_size[3]], tf.float32, tf.constant_initializer(0.0))\n",
    "        if groups == 1:\n",
    "            conv = tf.nn.conv2d(inputs, kernel, stride, padding=padding)\n",
    "        else:\n",
    "            input_groups = tf.split(inputs, groups, 3)\n",
    "            kernel_groups = tf.split(kernel, groups, 3)\n",
    "            output_groups = [tf.nn.conv2d(i, k, stride, padding=padding) for i, k in zip(input_groups, kernel_groups)]\n",
    "            conv = tf.concat(output_groups, 3)\n",
    "            \n",
    "        conv = tf.verify_tensor_all_finite(conv, name + ' infinite error!!!')\n",
    "        return tf.nn.relu(conv + biases, name=scope.name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc(name, inputs, output_size, relu=True):\n",
    "    # inputs should be flattened to a 2D tensor\n",
    "    input_size = int(inputs.get_shape()[1])\n",
    "    with tf.variable_scope(name) as scope:\n",
    "        W = tf.get_variable('weights', [input_size, output_size], tf.float32, \n",
    "                            tf.truncated_normal_initializer(stddev=math.sqrt(2.0/input_size)),\n",
    "                            tf.nn.l2_loss)\n",
    "        b = tf.get_variable('biases', [output_size], tf.float32, tf.constant_initializer(0.0))\n",
    "        out = tf.verify_tensor_all_finite(tf.matmul(inputs, W) + b, name + ' inifite error!!!')\n",
    "        if relu:\n",
    "            return tf.nn.relu(out, name=scope.name)\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference_deep(images, keep_prob, keypts=None):\n",
    "    # 1st layer\n",
    "    conv1 = conv_relu('conv1', images, [11, 11, 3, 96], [1, 4, 4, 1], 'VALID', 1)\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1, alpha=2e-5, beta=0.75,\n",
    "                                              depth_radius=2, bias=1.0, name='lrn1')\n",
    "    pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    \n",
    "    # 2nd layer\n",
    "    conv2 = conv_relu('conv2', pool1, [5, 5, 96, 256], [1, 1, 1, 1], 'SAME', 2)\n",
    "    lrn2 = tf.nn.local_response_normalization(conv2, alpha=2e-5, beta=0.75, \n",
    "                                              depth_radius=2, bias=1.0, name='lrn2')\n",
    "    pool2 = tf.nn.max_pool(lrn2, ksize=[1, 3, 3, 1], \n",
    "                           strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "    \n",
    "    # 3rd layer\n",
    "    conv3 = conv_relu('conv3', pool2, [3, 3, 256, 384], [1, 1, 1, 1], 'SAME', 1)\n",
    "        \n",
    "    # 4th layer\n",
    "    conv4 = conv_relu('conv4', conv3, [3, 3, 384, 384], [1, 1, 1, 1], 'SAME', 2)\n",
    "        \n",
    "    # 5th layer\n",
    "    conv5 = conv_relu('conv5', conv4, [3, 3, 384, 256], [1, 1, 1, 1], 'SAME', 2)\n",
    "    pool5 = tf.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool5')\n",
    "    \n",
    "    # 6th layer\n",
    "    pool5_flat = tf.reshape(pool5, [-1, 6 * 6 * 256])\n",
    "    if keypts is not None:\n",
    "        pool5_flat = tf.concat([pool5_flat, keypts], axis=1)\n",
    "    \n",
    "    fc6 = fc('fc6', pool5_flat, 4096)\n",
    "    \n",
    "    # drop out\n",
    "    fc6_drop = tf.nn.dropout(fc6, keep_prob)\n",
    "    \n",
    "    # 7th layer\n",
    "    fc7 = fc('fc7', fc6_drop, 4096)\n",
    "    \n",
    "    # drop out\n",
    "    fc7_drop = tf.nn.dropout(fc7, keep_prob)\n",
    "    \n",
    "    # readout layer\n",
    "    fc8 = fc('fc8', fc7_drop, 40, relu=False)\n",
    "    \n",
    "    return fc8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pretrained_weights(skip_layers, set_untrainable=True, warm_start=False):\n",
    "    weights = np.load('bvlc_alexnet.npy').item()\n",
    "    ops = []\n",
    "    trainables = tf.get_collection_ref(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    regularizations = tf.get_collection_ref(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    for layer in weights:\n",
    "        if layer not in skip_layers or warm_start:\n",
    "            with tf.variable_scope(layer, reuse=True) as scope:\n",
    "                kernel = tf.get_variable('weights')\n",
    "                ops.append(tf.assign(kernel, weights[layer][0]))\n",
    "                biases = tf.get_variable('biases')\n",
    "                ops.append(tf.assign(biases, weights[layer][1]))\n",
    "                if set_untrainable:\n",
    "                    trainables.remove(kernel)\n",
    "                    trainables.remove(biases)\n",
    "                    regularizations.remove(tf.losses.get_regularization_losses(scope.name)[0])\n",
    "    return tf.group(*ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits, labels, wd):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            labels=labels, logits=logits))\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    return cross_entropy + wd * tf.add_n(reg_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(loss, global_step):\n",
    "    lr = tf.train.exponential_decay(0.01, global_step, 5000, 0.1, True)\n",
    "    opt = tf.train.GradientDescentOptimizer(lr)\n",
    "    train_op = opt.minimize(loss, global_step)\n",
    "    variable_averages = tf.train.ExponentialMovingAverage(0.999, global_step)\n",
    "    variable_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    with tf.control_dependencies([train_op, variable_averages_op]):\n",
    "        op = tf.no_op()\n",
    "    return op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(train_from_scratch=False):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "        with tf.device('/cpu:0'):\n",
    "            images, labels, keypts = distorted_inputs(128)\n",
    "\n",
    "        pred = inference_deep(images, 0.5)\n",
    "        total_loss = loss(pred, labels, 0.000)\n",
    "        train_op = train(total_loss, global_step)\n",
    "        \n",
    "        skip_layers = ['fc7', 'fc8']\n",
    "        load_op = load_pretrained_weights(skip_layers)\n",
    "\n",
    "        class _LoggerHook(tf.train.SessionRunHook):\n",
    "            def begin(self):\n",
    "                self._step = -1\n",
    "                self._start_time = time.time()\n",
    "\n",
    "            def before_run(self, run_context):\n",
    "                self._step += 1\n",
    "                if self._step % 2 == 0:\n",
    "                    return tf.train.SessionRunArgs([total_loss, pred])\n",
    "                else:\n",
    "                    return None\n",
    "\n",
    "            def after_run(self, run_context, run_values):\n",
    "                if self._step % 2 == 0 :\n",
    "                    current_time = time.time()\n",
    "                    duration = current_time - self._start_time\n",
    "                    self._start_time = current_time\n",
    "                    print self._step\n",
    "#                     loss_val = run_values.results\n",
    "#                     format_str = '%s: step %d, loss = %.3f'\n",
    "#                     print format_str % (datetime.now(), self._step, loss_val)\n",
    "                if self._step == 0 or self._step == 1:\n",
    "                    print tf.trainable_variables()\n",
    "                    print run_values\n",
    "\n",
    "        with tf.train.MonitoredTrainingSession(\n",
    "            checkpoint_dir='./tmp/ckpt',\n",
    "            hooks=[tf.train.StopAtStepHook(last_step=10000),\n",
    "                  tf.train.NanTensorHook(total_loss),\n",
    "                  _LoggerHook()]\n",
    "        ) as sess:\n",
    "            if not train_from_scratch:\n",
    "                sess.run(load_op)\n",
    "            while not sess.should_stop():\n",
    "                sess.run(train_op)\n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt/model.ckpt-1872\n",
      "INFO:tensorflow:Saving checkpoints for 1872 into ./tmp/ckpt/model.ckpt.\n",
      "0\n",
      "[<tf.Variable 'fc7/weights:0' shape=(4096, 4096) dtype=float32_ref>, <tf.Variable 'fc7/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'fc8/weights:0' shape=(4096, 40) dtype=float32_ref>, <tf.Variable 'fc8/biases:0' shape=(40,) dtype=float32_ref>]\n",
      "SessionRunValues(results=[3.2488077, array([[ 6.47529507,  3.69093847,  0.06187304, ...,  3.8311131 ,\n",
      "         2.70871902,  2.37528276],\n",
      "       [ 4.05583143,  0.64246082, -2.12692833, ...,  4.54955339,\n",
      "         3.39035416,  4.54177475],\n",
      "       [ 1.97912729,  1.39414263,  2.35173225, ...,  2.63558483,\n",
      "        -0.29836708, -0.60502499],\n",
      "       ..., \n",
      "       [ 2.61232233,  0.77746058,  0.5801785 , ...,  4.08888531,\n",
      "         1.03738391, -0.12266219],\n",
      "       [ 3.08311725,  0.60599864,  1.21579325, ...,  1.55250072,\n",
      "         0.41512385,  1.49125528],\n",
      "       [ 0.17418548,  1.10245979,  2.10012364, ...,  1.80809522,\n",
      "         2.48862267,  2.74023128]], dtype=float32)], options=, run_metadata=)\n",
      "[<tf.Variable 'fc7/weights:0' shape=(4096, 4096) dtype=float32_ref>, <tf.Variable 'fc7/biases:0' shape=(4096,) dtype=float32_ref>, <tf.Variable 'fc8/weights:0' shape=(4096, 40) dtype=float32_ref>, <tf.Variable 'fc8/biases:0' shape=(40,) dtype=float32_ref>]\n",
      "SessionRunValues(results=None, options=, run_metadata=)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-58ca95c5b364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-337d50ba2786>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(train_from_scratch)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    503\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    840\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    843\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pduan/tensorflow/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(train=False, batch_size=1000):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        if train:\n",
    "            images, labels, _ = distorted_inputs(batch_size)\n",
    "        else:\n",
    "            images, labels, _ = inputs(batch_size)\n",
    "        pred = inference_deep(images, 0.5)\n",
    "        cost = loss(pred, labels, 0.0000)\n",
    "        top_k_op = tf.nn.in_top_k(pred, labels, 1)\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(0.999)\n",
    "        variables_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variables_to_restore)\n",
    "#         summary_op = tf.summary.merge_all()\n",
    "#         summary_write = tf.summary.FileWriter('./tmp/eval', g)\n",
    "        with tf.Session() as sess:\n",
    "            ckpt = tf.train.get_checkpoint_state('./tmp/ckpt')\n",
    "            if ckpt and ckpt.model_checkpoint_path:\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                print 'No checkpoint file found'\n",
    "                return\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(sess, coord)\n",
    "            try:\n",
    "#                 true_count = np.sum(sess.run(top_k_op))\n",
    "#                 precision = float(true_count) / batch_size\n",
    "#                 print 'precision: %.3f' % precision\n",
    "                print sess.run(cost)\n",
    "            except Exception as e:\n",
    "                print e\n",
    "            coord.request_stop()\n",
    "            coord.join(threads, stop_grace_period_secs=10)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tmp/ckpt/model.ckpt-1872\n",
      "1.47241\n"
     ]
    }
   ],
   "source": [
    "evaluate(train=True, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
